{"componentChunkName":"component---src-templates-project-details-js","path":"/projects/sdc-cnn-model/","result":{"data":{"markdownRemark":{"html":"<h2>Comprehensive Guide to Autonomous Driving using CNN and OpenCV</h2>\n<h4>Github: <a href=\"https://github.com/Walid-Birouk/\">Repository.</a></h4>\n<h2>Introduction</h2>\n<p>This documentation details the development and comparison of two distinct approaches for steering angle prediction in autonomous vehicles. The project integrates Convolutional Neural Network (CNN) models and traditional computer vision techniques using OpenCV, highlighting their application in steering a virtual car within Unity's simulation environment.</p>\n<h2><span>Ⅰ.</span> Project Overview</h2>\n<p>The initiative splits into distinct phases: data handling, model training using CNN, and an OpenCV-based approach for real-time driving simulation. Each method aims to autonomously control the steering angle of a simulated car, relying on different principles of image processing and machine learning.</p>\n<h3>Data Handling</h3>\n<p>The foundational step involves preprocessing image data captured from the vehicle's cameras. Simplifying file paths and extracting relevant features ensure streamlined data analysis and manipulation.</p>\n<h3>CNN for Steering Angle Prediction</h3>\n<p>A CNN model, designed and trained on processed image data, predicts steering angles to navigate the vehicle. This deep learning approach analyzes the visual inputs in a comprehensive manner, learning complex patterns and features essential for accurate steering control.</p>\n<h4>Key Features:</h4>\n<ul>\n<li><strong>Exploratory Data Analysis</strong>: Identifies biases in steering angle distribution, crucial for dataset balancing.</li>\n<li><strong>Data Augmentation</strong>: Enhances model robustness by introducing variability in the training dataset.</li>\n<li><strong>Model Architecture</strong>: Employs convolutional, flattening, and fully connected layers to process and learn from input images.</li>\n</ul>\n<h3>OpenCV Approach for Autonomous Driving</h3>\n<p>An alternative methodology utilizes OpenCV for image preprocessing, edge detection, and lane line identification. This approach focuses on detecting lane lines and calculating the steering angle based on the geometry of the detected lines.</p>\n<h4>Process Flow:</h4>\n<ul>\n<li><strong>Image Preprocessing</strong>: Converts images to grayscale, applies Gaussian blur, and detects edges using the Canny edge detector.</li>\n<li><strong>Region of Interest Selection</strong>: Masks the edge-detected image to focus on the likely lane line areas.</li>\n<li><strong>Lane Line Detection</strong>: Uses the Hough Transform method to detect lines and calculate the steering angle based on their orientation.</li>\n</ul>\n<h3>Real-Time Prediction and Vehicle Control</h3>\n<p>Both methods employ a <code>socketio</code> server interfacing with Unity's simulation for real-time vehicle control. The CNN approach uses a <code>drive.py</code> script, whereas the OpenCV technique is implemented in <code>opencvdrive.py</code>, each receiving live image data and sending back steering angles and throttle commands to the simulation.</p>\n<h2><span>Ⅱ.</span> Comparative Analysis: CNN vs. OpenCV</h2>\n<p>The CNN model, leveraging deep learning, offers a more nuanced understanding of the driving environment by learning from a vast array of visual features. This method excels in complex scenarios, adapting to various lighting conditions, and detecting subtle cues for navigation.</p>\n<p>Conversely, the OpenCV approach, grounded in traditional computer vision techniques, provides a straightforward, geometrically-driven method for steering angle prediction. While effective in clear, well-defined environments, its performance may degrade in visually complex or poorly lit conditions.</p>\n<h2><span>Ⅲ.</span> Conclusion</h2>\n<p>The CNN-based approach generally outperforms the OpenCV method in terms of versatility and accuracy in diverse driving scenarios. Deep learning models, trained on extensive datasets, capture the intricacies of the driving environment more effectively, leading to superior predictive performance.</p>\n<p>This project demonstrates the potential of CNNs in autonomous driving systems, offering insights into their development and deployment. Future work may explore hybrid models that combine deep learning with traditional computer vision techniques for enhanced performance.</p>\n<h2>Acknowledgments</h2>\n<p>Special thanks to Unity for providing a simulation environment conducive to the development and testing of autonomous driving models. This project underscores the collaborative efforts between machine learning and computer vision communities in advancing autonomous vehicle technologies.</p>","frontmatter":{"title":"Autonomous Driving Car (Unity)","stack":"TensorFlow & Flask & Open CV","images":[{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#384858","images":{"fallback":{"src":"/static/b38a8e6de118854d428ad812b62ba876/77779/sdc0.png","srcSet":"/static/b38a8e6de118854d428ad812b62ba876/63619/sdc0.png 448w,\n/static/b38a8e6de118854d428ad812b62ba876/bffbd/sdc0.png 896w,\n/static/b38a8e6de118854d428ad812b62ba876/77779/sdc0.png 1792w","sizes":"(min-width: 1792px) 1792px, 100vw"},"sources":[{"srcSet":"/static/b38a8e6de118854d428ad812b62ba876/c9dbf/sdc0.webp 448w,\n/static/b38a8e6de118854d428ad812b62ba876/7112f/sdc0.webp 896w,\n/static/b38a8e6de118854d428ad812b62ba876/fb23b/sdc0.webp 1792w","type":"image/webp","sizes":"(min-width: 1792px) 1792px, 100vw"}]},"width":1792,"height":1024}}},{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/static/2aef5223adcbb4ceb0c500f5daa6c395/a15b8/sdc1.png","srcSet":"/static/2aef5223adcbb4ceb0c500f5daa6c395/643f8/sdc1.png 462w,\n/static/2aef5223adcbb4ceb0c500f5daa6c395/19168/sdc1.png 924w,\n/static/2aef5223adcbb4ceb0c500f5daa6c395/a15b8/sdc1.png 1847w","sizes":"(min-width: 1847px) 1847px, 100vw"},"sources":[{"srcSet":"/static/2aef5223adcbb4ceb0c500f5daa6c395/9d63e/sdc1.webp 462w,\n/static/2aef5223adcbb4ceb0c500f5daa6c395/1e978/sdc1.webp 924w,\n/static/2aef5223adcbb4ceb0c500f5daa6c395/29d5c/sdc1.webp 1847w","type":"image/webp","sizes":"(min-width: 1847px) 1847px, 100vw"}]},"width":1847,"height":997}}},{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#181818","images":{"fallback":{"src":"/static/995f5231380ee2bf1ce94120c912aa2e/a4124/sdc2.png","srcSet":"/static/995f5231380ee2bf1ce94120c912aa2e/978ad/sdc2.png 465w,\n/static/995f5231380ee2bf1ce94120c912aa2e/2f51a/sdc2.png 930w,\n/static/995f5231380ee2bf1ce94120c912aa2e/a4124/sdc2.png 1859w","sizes":"(min-width: 1859px) 1859px, 100vw"},"sources":[{"srcSet":"/static/995f5231380ee2bf1ce94120c912aa2e/91d0b/sdc2.webp 465w,\n/static/995f5231380ee2bf1ce94120c912aa2e/6f5be/sdc2.webp 930w,\n/static/995f5231380ee2bf1ce94120c912aa2e/a647b/sdc2.webp 1859w","type":"image/webp","sizes":"(min-width: 1859px) 1859px, 100vw"}]},"width":1859,"height":1001}}},{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/304d5a4739657a3426ef384f7af67f1d/75b38/sdc3.png","srcSet":"/static/304d5a4739657a3426ef384f7af67f1d/bd256/sdc3.png 341w,\n/static/304d5a4739657a3426ef384f7af67f1d/23741/sdc3.png 681w,\n/static/304d5a4739657a3426ef384f7af67f1d/75b38/sdc3.png 1362w","sizes":"(min-width: 1362px) 1362px, 100vw"},"sources":[{"srcSet":"/static/304d5a4739657a3426ef384f7af67f1d/5020b/sdc3.webp 341w,\n/static/304d5a4739657a3426ef384f7af67f1d/881c9/sdc3.webp 681w,\n/static/304d5a4739657a3426ef384f7af67f1d/53dc6/sdc3.webp 1362w","type":"image/webp","sizes":"(min-width: 1362px) 1362px, 100vw"}]},"width":1362,"height":540}}}]}}},"pageContext":{"slug":"sdc-cnn-model"}},"staticQueryHashes":["1732862183","1965041683"],"slicesMap":{}}