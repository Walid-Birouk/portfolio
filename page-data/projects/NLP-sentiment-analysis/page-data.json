{"componentChunkName":"component---src-templates-project-details-js","path":"/projects/NLP-sentiment-analysis/","result":{"data":{"markdownRemark":{"html":"<h2>Understanding and Combating Online Toxicity with AI</h2>\n<h4>Github: <a href=\"https://github.com/Walid-Birouk/NLP-for-Sentiment-Analysis\">Repository.</a></h4>\n<h2><span>Ⅰ</span> Introduction</h2>\n<p>Welcome to our exploration into leveraging artificial intelligence (AI) to identify and classify toxic comments on digital platforms. This endeavor aims to enhance online interactions, making them healthier and more positive by automatically detecting and moderating harmful content.</p>\n<h2><span>Ⅱ</span> The Challenge of Online Toxicity</h2>\n<p>The proliferation of toxic comments on social media and other online platforms has become a significant issue, detracting from meaningful conversations and, in many cases, harming individuals' mental well-being. Addressing this challenge requires not just human moderation but the scalability and nuance understanding that AI technologies offer.</p>\n<h2><span>Ⅲ</span> Our Approach</h2>\n<p>Our project utilizes cutting-edge NLP techniques, drawing upon the power of pretrained models from the Hugging Face Transformers library. Specifically, we employ the <code>microsoft/Multilingual-MiniLM-L12-H384</code> model, known for its effectiveness in multilingual text classification tasks, to discern between toxic and non-toxic comments.</p>\n<h3>Key Features</h3>\n<ul>\n<li>\n<p><strong>Data Preprocessing</strong>: We begin by cleaning our text data, ensuring it's in a format conducive to model training. This includes addressing the prevalent issue of class imbalance through techniques like undersampling.</p>\n</li>\n<li>\n<p><strong>Model Training</strong>: Leveraging a binary classification approach, we train our model to accurately identify toxic comments, using a dataset that reflects the diverse nature of online discourse.</p>\n</li>\n<li>\n<p><strong>Evaluation</strong>: Through rigorous testing, we assess our model's accuracy and reliability, ensuring it can be a valuable tool in real-world applications.</p>\n</li>\n</ul>\n<h2><span>Ⅳ</span> Insights and Findings</h2>\n<p>Our project highlights several key insights:</p>\n<ul>\n<li>\n<p><strong>Class Imbalance</strong>: A significant challenge in toxic comment classification is the imbalance between toxic and non-toxic comments. Our methodology effectively addresses this, improving model sensitivity to toxic content.</p>\n</li>\n<li>\n<p><strong>Model Performance</strong>: The pretrained <code>Multilingual-MiniLM</code> model demonstrates promising capabilities in accurately classifying comments, showcasing the potential of AI in content moderation.</p>\n</li>\n<li>\n<p><strong>Future Directions</strong>: The evolving nature of language and online communication necessitates ongoing model training and adaptation, pointing towards the importance of continuous learning in AI applications.</p>\n</li>\n</ul>\n<h2><span>Ⅴ</span> Conclusion</h2>\n<p>By harnessing the capabilities of AI and NLP, we can make significant strides in combating online toxicity. This project serves as a step towards creating safer digital spaces, where users can engage in constructive and positive interactions. As we move forward, the integration of such technologies in content moderation strategies will be crucial in fostering inclusivity and respect across online platforms.</p>","frontmatter":{"title":"NLP model for sentiment analysis","stack":"Hugging Face & PyTorch","images":[{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#b8c8e8","images":{"fallback":{"src":"/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/813a3/nlp1.png","srcSet":"/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/b90fe/nlp1.png 302w,\n/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/a6f63/nlp1.png 605w,\n/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/813a3/nlp1.png 1209w","sizes":"(min-width: 1209px) 1209px, 100vw"},"sources":[{"srcSet":"/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/a1ed6/nlp1.webp 302w,\n/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/1b134/nlp1.webp 605w,\n/portfolio/static/1b6c64ecd2e542999fdc9bd2a500219f/0e846/nlp1.webp 1209w","type":"image/webp","sizes":"(min-width: 1209px) 1209px, 100vw"}]},"width":1209,"height":624}}},{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/portfolio/static/9f941091e3f55a997a28f493d1ca819f/051b0/nlp2.png","srcSet":"/portfolio/static/9f941091e3f55a997a28f493d1ca819f/903b1/nlp2.png 400w,\n/portfolio/static/9f941091e3f55a997a28f493d1ca819f/f3bd0/nlp2.png 800w,\n/portfolio/static/9f941091e3f55a997a28f493d1ca819f/051b0/nlp2.png 1599w","sizes":"(min-width: 1599px) 1599px, 100vw"},"sources":[{"srcSet":"/portfolio/static/9f941091e3f55a997a28f493d1ca819f/5077a/nlp2.webp 400w,\n/portfolio/static/9f941091e3f55a997a28f493d1ca819f/fb743/nlp2.webp 800w,\n/portfolio/static/9f941091e3f55a997a28f493d1ca819f/9e7b6/nlp2.webp 1599w","type":"image/webp","sizes":"(min-width: 1599px) 1599px, 100vw"}]},"width":1599,"height":348.99999999999994}}},{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/fc2c7/nlp3.png","srcSet":"/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/94381/nlp3.png 401w,\n/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/4f847/nlp3.png 802w,\n/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/fc2c7/nlp3.png 1604w","sizes":"(min-width: 1604px) 1604px, 100vw"},"sources":[{"srcSet":"/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/ce69c/nlp3.webp 401w,\n/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/883eb/nlp3.webp 802w,\n/portfolio/static/2baa40a2eb01cc2c06c56db5e0fec56b/2e5fd/nlp3.webp 1604w","type":"image/webp","sizes":"(min-width: 1604px) 1604px, 100vw"}]},"width":1604,"height":653}}}]}}},"pageContext":{"slug":"NLP-sentiment-analysis"}},"staticQueryHashes":["1732862183","1965041683"],"slicesMap":{}}